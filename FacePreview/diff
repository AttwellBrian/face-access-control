diff --git a/FacePreview/AndroidManifest.xml b/FacePreview/AndroidManifest.xml
index d99971f..d455ae2 100644
--- a/FacePreview/AndroidManifest.xml
+++ b/FacePreview/AndroidManifest.xml
@@ -10,8 +10,8 @@
       <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
       <application android:label="@string/app_name">
           <activity
-              android:name="Introduction"
-              android:label="Introduction"
+              android:name="Launcher"
+              android:label="Face Unlock"
               android:theme="@android:style/Theme.Holo.Light"
               android:screenOrientation="landscape">
               <intent-filter>
@@ -20,8 +20,17 @@
               </intent-filter>
           </activity>
           <activity
+              android:name="Introduction"
+              android:label="Face Unlock"
+              android:theme="@android:style/Theme.Holo.Light"
+              android:screenOrientation="landscape">
+          </activity>
+          <activity
+              android:name="com.googlecode.javacv.facepreview.LockScreen"
+              android:theme="@android:style/Theme.Holo.Light"
+              android:screenOrientation="landscape" />
+          <activity
               android:name="com.googlecode.javacv.facepreview.AuthorizationSetup"
-              android:label="@string/app_name"
               android:theme="@android:style/Theme.Holo.Light"
               android:screenOrientation="landscape" />
 		  <activity
diff --git a/FacePreview/FacePreview_Test/src/com/googlecode/javacv/facepreview/Test_FacePredictor.java b/FacePreview/FacePreview_Test/src/com/googlecode/javacv/facepreview/Test_FacePredictor.java
index aa994d2..d3a15e1 100644
--- a/FacePreview/FacePreview_Test/src/com/googlecode/javacv/facepreview/Test_FacePredictor.java
+++ b/FacePreview/FacePreview_Test/src/com/googlecode/javacv/facepreview/Test_FacePredictor.java
@@ -144,5 +144,41 @@ public class Test_FacePredictor extends AndroidTestCase {
 		assertTrue(facePredictor.authenticate(image));
 	}
 	
+	public void testBlackAndWhite() throws Exception {
+		// Use testing image from training set, as a sanity test
+		File imageFile = Loader.extractResource(getClass(),
+				"/com/googlecode/javacv/facepreview/data/a_05_05.jpg",
+				getContext().getCacheDir(), "image", ".jpg");
+	    IplImage image = cvLoadImage(imageFile.getAbsolutePath());
+	    String name = facePredictor.identify(image).first;
+	    assertEquals("5", name);
+	}
+	
+	
+	public void testSavingAndLoading() throws Exception {
+		facePredictor.save(getContext(), "file.xml");
+		
+		FacePredictor facePredictor2 = facePredictor;
+		facePredictor = new FacePredictor(getContext(), "file.xml");
+		testRecognizeForthPerson();
+		facePredictor = facePredictor2;
+	}
+
+	// This is allowed to fail
+	public void testCurrentRecognizer() throws Exception {
+		FacePredictor facePredictor2 = facePredictor;
+		facePredictor = new FacePredictor(getContext(), "recognizer.xml");
+		testRecognizeForthPerson();
+		facePredictor = facePredictor2;
+	}
+	
+	public void testNoFace() throws Exception {
+		File imageFile = Loader.extractResource(getClass(),
+				"/com/googlecode/javacv/facepreview/data/no_face.jpg",
+				getContext().getCacheDir(), "image", ".jpg");
+	    IplImage image = cvLoadImage(imageFile.getAbsolutePath());
+	    String name = facePredictor.identify(image).first;
+	    assertEquals(null, name);
+	}
 	
 }
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/AuthorizationSetup.java b/FacePreview/src/com/googlecode/javacv/facepreview/AuthorizationSetup.java
index 95e5fb4..ad13592 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/AuthorizationSetup.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/AuthorizationSetup.java
@@ -88,8 +88,13 @@ public class AuthorizationSetup extends Activity {
 					
 					// TODO: instead of copying grayImage, copy the full image.
 					// since this gets called on UI thread, shouldn't be any issue directly grabbing the entire grayImage
-					IplImage copiedImage = new IplImage(faceView.grayImage);
-					grayImages.add(copiedImage);
+					try {
+						IplImage copiedImage = new IplImage(faceView.grayImage);
+						grayImages.add(copiedImage);
+					} catch (Exception e) {
+						// catch phony exception that gets thrown as warning
+					}
+					
 					
 					// TODO: initialize faceView.displayedText  somewhere
 					
@@ -105,19 +110,24 @@ public class AuthorizationSetup extends Activity {
 						faceView.displayedText = "Tap the screen to set the FINAL picture of your face - This side up.";
 						cvSaveImage(getApplicationContext().getFilesDir() + "/face_image_2.jpg", faceView.grayImage);
 					} else if (grayImages.size() == 3) {
+						text = "Final image is securely set";
 						cvSaveImage(getApplicationContext().getFilesDir() + "/face_image_3.jpg", faceView.grayImage);
 						
 						// Kick off the computation of the histograms into a seperate thread. Ideally, we
 						// would have already started this service.		
 						final RecognizerService service = mBoundService;
 						new AsyncTask<RecognizerService, Void, Void>() {
-							protected void doInBackground(RecognizerService service) {
-								service.initPredictor();
-							}
 							@Override
 							protected Void doInBackground(RecognizerService... params) {
+								service.initPredictor();
 								return null;
 							}
+							@Override
+							protected void onPostExecute(Void result) {
+								int duration = Toast.LENGTH_SHORT;
+								Toast toast = Toast.makeText(getApplicationContext(), "Recognizer Initialization is complete", duration);
+								toast.show();	
+							}
 						}.execute();
 						
 						// Tell the user they are finished with their authorization. Don't let them
@@ -140,6 +150,12 @@ public class AuthorizationSetup extends Activity {
         
     }
     
+    @Override
+    protected void onDestroy() {
+    	unbindService(mConnection);
+    	super.onDestroy();
+    }
+    
     private RecognizerService mBoundService;
     private ServiceConnection mConnection = new ServiceConnection() {
     	public void onServiceConnected(ComponentName className, IBinder service) {
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/CompletedAuthorization.java b/FacePreview/src/com/googlecode/javacv/facepreview/CompletedAuthorization.java
index cdedd88..9f0bcfb 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/CompletedAuthorization.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/CompletedAuthorization.java
@@ -20,8 +20,9 @@ public class CompletedAuthorization extends Activity {
         textView.setOnClickListener(new OnClickListener() {
 			@Override
 			public void onClick(View v) {
-				//Intent myIntent = new Intent(CompletedAuthorization.this, FacePreview.class);
-				//CompletedAuthorization.this.startActivity(myIntent);				
+				Intent intent = new Intent(CompletedAuthorization.this, LockScreen.class);
+				intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP);
+				CompletedAuthorization.this.startActivity(intent);				
 			}
 		});
     }
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/FacePredictor.java b/FacePreview/src/com/googlecode/javacv/facepreview/FacePredictor.java
index ef9021c..628b04d 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/FacePredictor.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/FacePredictor.java
@@ -11,6 +11,7 @@ import static com.googlecode.javacv.cpp.opencv_core.cvGetSize;
 import static com.googlecode.javacv.cpp.opencv_core.cvLoad;
 import static com.googlecode.javacv.cpp.opencv_core.cvSetImageROI;
 import static com.googlecode.javacv.cpp.opencv_highgui.cvLoadImage;
+import static com.googlecode.javacv.cpp.opencv_highgui.cvSaveImage;
 import static com.googlecode.javacv.cpp.opencv_imgproc.CV_BGR2GRAY;
 import static com.googlecode.javacv.cpp.opencv_imgproc.CV_INTER_LINEAR;
 import static com.googlecode.javacv.cpp.opencv_imgproc.cvCvtColor;
@@ -57,7 +58,7 @@ public class FacePredictor {
     private Context context; // store for debugging
     
     // Save IplImage to disk, so we can look at it later
-    private static void debugPrintIplImage(IplImage src, Context context) {
+    public static void debugPrintIplImage(IplImage src, Context context) {
     	Bitmap tmpbitmap = IplImageToBitmap(src);
         MediaStore.Images.Media.insertImage(context.getContentResolver(), tmpbitmap, "image" + Calendar.getInstance().get(Calendar.SECOND) + debugPictureCount++ , "temp");
     }
@@ -66,7 +67,7 @@ public class FacePredictor {
     private static Bitmap IplImageToBitmap(IplImage src) {//don't need to do this anymore... can use the cvSave function
         int width = src.width();
         int height = src.height();
-        int smallFactor = 8;
+        int smallFactor = 4;
         Bitmap bitmap = Bitmap.createBitmap(width/smallFactor, height/smallFactor, Bitmap.Config.ARGB_8888);
         for(int r=0;r<height/smallFactor;r+=1) {
             for(int c=0;c<width/smallFactor;c+=1) {
@@ -95,29 +96,45 @@ public class FacePredictor {
       names.put(personCount, name);
   }
   
+  // Load from file
+  public FacePredictor(Context applicationContext, String filename) throws Exception {
+	    File file = new File(applicationContext.getFilesDir() + "/" + filename);
+	    if (!file.exists()) {
+	    	throw new Exception();
+	    }
+	    
+	    this.context = applicationContext;
+	    loadClassifier();
+	  	algorithm = ALGO_FACTORY;
+	    algorithm.load(context.getExternalFilesDir(null).getAbsolutePath() + "/" + filename);
+  }
+  
+  private void loadClassifier() throws IOException {
+	// Load the classifier file from Java resources.
+	    File classifierFile = Loader.extractResource(getClass(),
+	        "/com/googlecode/javacv/facepreview/data/haarcascade_frontalface_alt.xml",
+	        context.getCacheDir(), "classifier", ".xml");
+	    if (classifierFile == null || classifierFile.length() <= 0) {
+	        throw new IOException("Could not extract the classifier file from Java resource.");
+	    }
+	    // Preload the opencv_objdetect module to work around a known bug.
+	    Loader.load(opencv_objdetect.class);
+	    classifier = new CvHaarClassifierCascade(cvLoad(classifierFile.getAbsolutePath()));
+  }
+  
   // This is a slow function. It is slow, because it has to load a lot of images.
   // This doesn't need to be a problem. 
   public FacePredictor(Context context, IplImage [] authorizedImages) throws IOException {
     
     this.context = context;
-    
-    // Load the classifier file from Java resources.
-    File classifierFile = Loader.extractResource(getClass(),
-        "/com/googlecode/javacv/facepreview/data/haarcascade_frontalface_alt.xml",
-        context.getCacheDir(), "classifier", ".xml");
-    if (classifierFile == null || classifierFile.length() <= 0) {
-        throw new IOException("Could not extract the classifier file from Java resource.");
-    }
-    // Preload the opencv_objdetect module to work around a known bug.
-    Loader.load(opencv_objdetect.class);
-    classifier = new CvHaarClassifierCascade(cvLoad(classifierFile.getAbsolutePath()));
+    loadClassifier();
     
     final int numberOfImages = (8+1)*3; // TODO: calculate this more smartly.. maybe don't need to calculate
     final MatVector images = new MatVector(numberOfImages);
     final CvMat labels = cvCreateMat(1, numberOfImages, CV_32SC1);
    
     // TODO: process these images ahead of time (otherwise startup will take several minutes)
-    int imgCount = 0;  
+    int imgCount = 0;      
     for (int personCount = 2; personCount < 10; personCount++) { // training people 2-10
     	// TODO: use a couple images per person. We have the four images per person available. I'm just not using them.
         String fileName = String.format("/com/googlecode/javacv/facepreview/data/a_%02d_05.jpg", personCount);
@@ -149,9 +166,7 @@ public class FacePredictor {
 	  return name != null && name.equals("11");
   }
   
-  /**
-   * Identify the face in bounding box r in image
-   */
+  // NOT EVER USED
   Pair<String, Double> identify(IplImage image, CvRect face) {
     final IplImage iplImage = toTinyGray(image, face);
     final int[] prediction = new int[1];
@@ -161,13 +176,24 @@ public class FacePredictor {
     Double confidence_ = 100*(THRESHHOLD - confidence[0])/THRESHHOLD;
     return new Pair<String, Double>(name, confidence_); 
   }
-    
+  
+  // Input needs to be B
   public Pair<String, Double> identify(IplImage image) {
-    IplImage grayImage = IplImage.create(image.width(), image.height(), IPL_DEPTH_8U, 1);
-    cvCvtColor(image, grayImage, CV_BGR2GRAY);
+    // Convert to grayscale, if not already done
+	IplImage grayImage;
+    if (image.nChannels() == 1) {
+    	grayImage = image;
+    } else {
+    	grayImage = IplImage.create(image.width(), image.height(), IPL_DEPTH_8U, 1);
+    	cvCvtColor(image, grayImage, CV_BGR2GRAY);
+    }
+    
     CvRect faceRectangle = detectFace(grayImage);
+    if (faceRectangle.isNull()) {
+    	return new Pair<String, Double>(null, (double) 0); 
+    }
 	  
-    final IplImage iplImage = toTinyGray(image, faceRectangle);
+    final IplImage iplImage = toTiny(grayImage, faceRectangle);
     final int[] prediction = new int[1];
     final double[] confidence = new double[1];
     algorithm.predict(iplImage, prediction, confidence);
@@ -180,7 +206,6 @@ public class FacePredictor {
     }
     return new Pair<String, Double>(name, confidence_); 
   }
-    
 
   private static final CvMemStorage storage = CvMemStorage.create();
   private static CvHaarClassifierCascade classifier ;
@@ -190,11 +215,14 @@ public class FacePredictor {
    * This does facial detection and NOT facial recognition
    */
   private synchronized CvRect detectFace(IplImage image) {
-	cvClearMemStorage(storage);
-    
-    final CvSeq cvSeq = cvHaarDetectObjects(image, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
-    assert ( cvSeq.total() > 0);
-    return  new CvRect(cvGetSeqElem(cvSeq, 0));
+	synchronized (this) {//TODO: improve this
+		cvClearMemStorage(storage);
+	
+	    final CvSeq cvSeq = cvHaarDetectObjects(image, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
+	    assert !cvSeq.isNull();
+
+	    return new CvRect(cvGetSeqElem(cvSeq, 0));
+	}
   }
 
   private static final CvSize SMALL_IMAGE_SIZE = new CvSize(400,400);
@@ -204,18 +232,26 @@ public class FacePredictor {
    */
   private IplImage toTinyGray(IplImage image, CvRect r /* (x,y) is the top corner */) {
       IplImage gray = cvCreateImage(cvGetSize(image), IPL_DEPTH_8U, 1);
+      cvCvtColor(image, gray, CV_BGR2GRAY);		
+      return toTiny(gray, r);
+  }
+  
+  private IplImage toTiny(IplImage gray, CvRect r /* (x,y) is the top corner */) {
       IplImage roi = cvCreateImage(SMALL_IMAGE_SIZE, IPL_DEPTH_8U, 1);
 
       int width = Math.max(r.width(), r.height());
       int x = r.x() + (r.width()-width)/2;
       int y = r.y() + (r.height()-width)/2;
       
-      CvRect r1 = new CvRect(x, y, width, width);// consider adding +10 on all sides
-      cvCvtColor(image, gray, CV_BGR2GRAY);
-      cvSetImageROI(gray, r1);
+      CvRect r1 = new CvRect(x, y, width, width);// consider adding +10 on all sides									//THIS IS LIKELY FAILING!!!
+      cvSetImageROI(gray, r1);//set portion that will be processed on
       cvResize(gray, roi, CV_INTER_LINEAR);
       cvEqualizeHist(roi, roi);
       	//debugPrintIplImage(roi, context);
-      return roi;
+      return roi;  
   }
+
+	public void save(Context applicationContext, String filename) {		
+		algorithm.save(context.getExternalFilesDir(null).getAbsolutePath() + "/" + filename);
+	}
 }
\ No newline at end of file
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/LockScreen.java b/FacePreview/src/com/googlecode/javacv/facepreview/LockScreen.java
index 6b40c2a..738e08a 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/LockScreen.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/LockScreen.java
@@ -28,9 +28,10 @@ import android.widget.Toast;
 
 import com.googlecode.javacv.cpp.opencv_core.IplImage;
 import com.googlecode.javacv.facepreview.views.FaceView;
+import com.googlecode.javacv.facepreview.views.FaceView.FaceViewImageCallback;
 import com.googlecode.javacv.facepreview.views.Preview;
 
-public class LockScreen extends Activity {
+public class LockScreen extends Activity implements FaceView.FaceViewImageCallback {
     private FrameLayout layout;
     private FaceView faceView;
     private Preview mPreview;
@@ -45,13 +46,14 @@ public class LockScreen extends Activity {
 
         getWindow().addFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN);
 
-        bindService(new Intent(LockScreen.this, RecognizerService.class), mConnection, Context.BIND_AUTO_CREATE);
+        bindService(new Intent(LockScreen.this, RecognizerService.class), mConnection, Context.BIND_ABOVE_CLIENT);
         
         // Create our Preview view and set it as the content of our activity.
         try {
             layout = new FrameLayout(this);
             faceView = new FaceView(this);
             mPreview = new Preview(this, faceView);
+            faceView.setFaceViewImageCallback(this);
             layout.addView(mPreview);
             layout.addView(faceView);
             setContentView(layout);
@@ -62,6 +64,46 @@ public class LockScreen extends Activity {
         
     }
     
+    private static long lastUnixTime = System.currentTimeMillis();//don't use this for subsecond
+    
+	@Override
+	public void image(IplImage image) {
+
+		final IplImage ownedImage = image.clone();
+		final RecognizerService service = mBoundService;
+		if (service.facePredictor == null) {
+			return;
+		}
+		
+		// Rate limit the image analysis (should probably be done in the other function)
+		if (System.currentTimeMillis() <= lastUnixTime + 4000) {
+			return;
+		}
+		lastUnixTime = System.currentTimeMillis();
+		
+		new AsyncTask<RecognizerService, Void, Boolean>() {
+			@Override
+			protected Boolean doInBackground(RecognizerService... params) {
+				return service.facePredictor.authenticate(ownedImage);
+			}
+			@Override
+			protected void onPostExecute(Boolean result) {
+				if (result) {
+					//AlertDialog.Builder builder = new AlertDialog.Builder(LockScreen.this);
+					//builder.setMessage("You have unlocked the app!").setTitle("Success");
+					//AlertDialog dialog = builder.create();
+					//dialog.show();
+				}
+				
+				int duration = Toast.LENGTH_SHORT;
+				Toast toast = Toast.makeText(getApplicationContext(), "Debug: result = " + result, duration);
+				toast.show();
+				
+				// TODO: only let one of these async tasks execute at once (for performance reasons, not for correctness reasons)
+			}
+		}.execute();
+	}
+    
     private RecognizerService mBoundService;
     private ServiceConnection mConnection = new ServiceConnection() {
     	public void onServiceConnected(ComponentName className, IBinder service) {
@@ -79,4 +121,5 @@ public class LockScreen extends Activity {
     	        mBoundService = null;
     	    }
     	};
+
 }
\ No newline at end of file
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/RecognizerService.java b/FacePreview/src/com/googlecode/javacv/facepreview/RecognizerService.java
index 3696fc8..0b8674a 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/RecognizerService.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/RecognizerService.java
@@ -2,28 +2,17 @@ package com.googlecode.javacv.facepreview;
 
 import static com.googlecode.javacv.cpp.opencv_highgui.cvLoadImage;
 
-import java.io.FileDescriptor;
 import java.io.IOException;
-import java.util.List;
 
 import android.app.Service;
-import android.content.ComponentName;
 import android.content.Intent;
-import android.content.ServiceConnection;
 import android.os.Binder;
 import android.os.IBinder;
-import android.os.IInterface;
-import android.os.Parcel;
-import android.os.RemoteException;
-import android.widget.ArrayAdapter;
 import android.widget.Toast;
 
-import com.googlecode.javacpp.Loader;
 import com.googlecode.javacv.cpp.opencv_core.IplImage;
 
 // Assumption: unbinding doesn't happen
-// maybe this isn't the correct way to do this.
-// FORGET THIS SERVICE, JUST USE A SEPERATE THREAD
 // NO, USE A BOUND SERVICE (http://developer.android.com/guide/components/bound-services.html#Binder)
 
 public class RecognizerService extends Service {
@@ -33,11 +22,14 @@ public class RecognizerService extends Service {
 	
 	@Override
     public int onStartCommand(Intent intent, int flags, int startId) {
+		// try loading the the predictor from file
+		try {
+			facePredictor = new FacePredictor(this, "recognizer.xml");
+		} catch (Exception e) {
+			
+		}
         // We want this service to continue running until it is explicitly
         // stopped, so return sticky.
-		
-		//initPredictor();//should check if we are starting or not
-		
         return START_STICKY;//should consider changing this later
     }
 	
@@ -65,13 +57,15 @@ public class RecognizerService extends Service {
     
    
     public void initPredictor() {
-		try {
+		try {		
+			
 			IplImage [] authorizedImages = {
     				cvLoadImage(getApplicationContext().getFilesDir() + "/face_image_1.jpg"),
     				cvLoadImage(getApplicationContext().getFilesDir() + "/face_image_2.jpg"),
     				cvLoadImage(getApplicationContext().getFilesDir() + "/face_image_3.jpg")
     		};
 			facePredictor = new FacePredictor(this, authorizedImages);
+			facePredictor.save(this, "recognizer.xml");
 		} catch (IOException e) {
 			e.printStackTrace();
 		}
diff --git a/FacePreview/src/com/googlecode/javacv/facepreview/views/FaceView.java b/FacePreview/src/com/googlecode/javacv/facepreview/views/FaceView.java
index 60074a8..bb67428 100644
--- a/FacePreview/src/com/googlecode/javacv/facepreview/views/FaceView.java
+++ b/FacePreview/src/com/googlecode/javacv/facepreview/views/FaceView.java
@@ -4,31 +4,37 @@ import static com.googlecode.javacv.cpp.opencv_core.IPL_DEPTH_8U;
 import static com.googlecode.javacv.cpp.opencv_core.cvClearMemStorage;
 import static com.googlecode.javacv.cpp.opencv_core.cvGetSeqElem;
 import static com.googlecode.javacv.cpp.opencv_core.cvLoad;
-import static com.googlecode.javacv.cpp.opencv_objdetect.CV_HAAR_DO_CANNY_PRUNING;
-import static com.googlecode.javacv.cpp.opencv_objdetect.cvHaarDetectObjects;
+import static com.googlecode.javacv.cpp.opencv_highgui.cvSaveImage;
 
+import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 
 import android.content.Context;
+import android.graphics.Bitmap;
+import android.graphics.BitmapFactory;
 import android.graphics.Canvas;
 import android.graphics.Color;
+import android.graphics.ImageFormat;
 import android.graphics.Paint;
+import android.graphics.Rect;
+import android.graphics.YuvImage;
 import android.hardware.Camera;
 import android.view.View;
 
 import com.googlecode.javacpp.Loader;
 import com.googlecode.javacv.cpp.opencv_core.CvMemStorage;
 import com.googlecode.javacv.cpp.opencv_core.CvRect;
+import com.googlecode.javacv.cpp.opencv_core.CvScalar;
 import com.googlecode.javacv.cpp.opencv_core.CvSeq;
 import com.googlecode.javacv.cpp.opencv_core.IplImage;
 import com.googlecode.javacv.cpp.opencv_objdetect;
 import com.googlecode.javacv.cpp.opencv_objdetect.CvHaarClassifierCascade;
 
-
+// can we use startFaceDetection on camera? probably not
 public class FaceView extends View implements Camera.PreviewCallback {
-    public static final int SUBSAMPLING_FACTOR = 4;
+    public static final int SUBSAMPLING_FACTOR = 4;//4;//TODO: set this to 1
 
     public IplImage grayImage;
     public String displayedText = "Tap the screen to set your face - This side up.";    
@@ -36,13 +42,13 @@ public class FaceView extends View implements Camera.PreviewCallback {
     private CvHaarClassifierCascade classifier;
     private CvMemStorage storage;
     private CvSeq faces;
-
+    
     public FaceView(Context context) throws IOException {
         super(context);
  
         // Load the classifier file from Java resources.
         File classifierFile = Loader.extractResource(getClass(),
-            "/com/googlecode/javacv/facepreview/haarcascade_frontalface_alt.xml",
+            "/com/googlecode/javacv/facepreview/data/haarcascade_frontalface_alt.xml",
             context.getCacheDir(), "classifier", ".xml");
         if (classifierFile == null || classifierFile.length() <= 0) {
             throw new IOException("Could not extract the classifier file from Java resource.");
@@ -57,7 +63,7 @@ public class FaceView extends View implements Camera.PreviewCallback {
         }
         storage = CvMemStorage.create();
     }
-
+    
     public void onPreviewFrame(final byte[] data, final Camera camera) {
         try {
             Camera.Size size = camera.getParameters().getPreviewSize();
@@ -65,15 +71,32 @@ public class FaceView extends View implements Camera.PreviewCallback {
             camera.addCallbackBuffer(data);
         } catch (RuntimeException e) {
             // The camera has probably just been released, ignore.
+        	System.err.println(e.toString());
         }
     }
 
+    public interface FaceViewImageCallback {
+    	void image(IplImage image /*BGR*/);
+    }
+    public void setFaceViewImageCallback(FaceViewImageCallback callback) {
+    	mCallback = callback;
+    }
+    FaceViewImageCallback mCallback = null;
+    
+    // TODO: this more efficienty using built in API, or parallel for http://stackoverflow.com/questions/4010185/parallel-for-for-java
     protected void processImage(byte[] data, int width, int height) {
         // First, downsample our image and convert it into a grayscale IplImage
         int f = SUBSAMPLING_FACTOR;
         if (grayImage == null || grayImage.width() != width/f || grayImage.height() != height/f) {
-            grayImage = IplImage.create(width/f, height/f, IPL_DEPTH_8U, 1);
+        	try {
+        		grayImage = IplImage.create(width/f, height/f, IPL_DEPTH_8U, 1);
+        	} catch (Exception e) {
+        		// ignore exception. It is only a warning in this case
+        		System.err.println(e.toString());
+        	}
         }
+   
+    	// TODO: spead this up
         int imageWidth  = grayImage.width();
         int imageHeight = grayImage.height();
         int dataStride = f*width;
@@ -87,11 +110,47 @@ public class FaceView extends View implements Camera.PreviewCallback {
             }
         }
 
+
+        // TODO: use the full image
+        if (mCallback != null) {
+        	
+        	//f = 1;
+        	/*
+        	IplImage image = IplImage.create(width/f, height/f, IPL_DEPTH_8U, 1);
+            int imageWidth  = image.width();
+            int imageHeight = image.height();
+            int dataStride = f*width;
+            int imageStride = image.widthStep();
+            ByteBuffer imageBuffer = image.getByteBuffer();
+            for (int y = 0; y < imageHeight; y++) {
+                int dataLine = y*dataStride;
+                int imageLine = y*imageStride;
+                for (int x = 0; x < imageWidth; x++) {
+                    imageBuffer.put(imageLine + x, data[dataLine + f*x]);
+                }
+            }
+            */
+
+            if (debugPictureCount == 0) {
+            	debugPrintIplImage(grayImage, this.getContext());
+            }
+            mCallback.image(grayImage);
+        }
+        
         cvClearMemStorage(storage);
-        faces = cvHaarDetectObjects(grayImage, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
+        // TODO: make this asynchronous
+        //faces = cvHaarDetectObjects(grayImage, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
         postInvalidate();
     }
 
+    // todo; delete
+    static int debugPictureCount = 0;
+    private static void debugPrintIplImage(IplImage src, Context context) {
+    	File file = new File(context.getExternalFilesDir(null), "testimage_same.jpg");
+    	cvSaveImage(file.getAbsolutePath(), src);
+    	debugPictureCount++;
+    }
+    
     @Override
     protected void onDraw(Canvas canvas) {
         Paint paint = new Paint();
diff --git a/README.md b/README.md
index e1fcb8f..89dc67e 100644
--- a/README.md
+++ b/README.md
@@ -13,3 +13,6 @@ The two above components are not yet connected.
 ##Proposal
 
 https://docs.google.com/document/d/1qCn1KuC45r-uz-HTVkwYc8mqkEIqjNAC2T6LP0xs_6E/pub
+
+##Testing
+Source code for a test project are contained inside the FacePreview_Test project.
\ No newline at end of file
